# Flink å•å…ƒæµ‹è¯•(äºŒ)

æµ‹è¯•æ˜¯æ¯ä¸ªè½¯ä»¶å¼€å‘è¿‡ç¨‹ä¸­éƒ½ä¸å¯æˆ–ç¼ºçš„ä¸€éƒ¨åˆ†ï¼ŒåŒæ · Apache Flink ä¹Ÿæä¾›äº†ä¸€äº›å·¥å…·å¯ä»¥åœ¨æµ‹è¯•é‡‘å­—å¡”çš„å¤šä¸ªçº§åˆ«ä¸Šæµ‹è¯•ä½ çš„åº”ç”¨ç¨‹åºä»£ç ã€‚

## æµ‹è¯• UDF

é€šå¸¸ï¼Œæˆ‘ä»¬è®¤ä¸º Flink åœ¨ UDFï¼ˆuser-defined function ç”¨æˆ·å®šä¹‰çš„å‡½æ•°ï¼‰ä¹‹å¤–äº§ç”Ÿçš„æ˜¯æ­£ç¡®ç»“æœï¼Œå› æ­¤ï¼Œå»ºè®®å°½å¯èƒ½ç”¨å•å…ƒæµ‹è¯•æ¥æµ‹è¯•é‚£äº›åŒ…å«ä¸»è¦ä¸šåŠ¡é€»è¾‘çš„ç±»ã€‚

### å•å…ƒæµ‹è¯• Stateless,Timeless UDFs

è®©æˆ‘ä»¬ä¸¾ä¸€ä¸ªæ— çŠ¶æ€çš„ `MapFunction` çš„ä¾‹å­ï¼š

```java
public class IncrementMapFunction implements MapFunction<Long, Long> {

    private static final long serialVersionUID = 1L;

    @Override
    public Long map(Long value) throws Exception {
        return value + 1;
    }
}
```

ä¸ºè¿™ä¸ªå‡½æ•°ç¼–å†™å•å…ƒæµ‹è¯•æ˜¯éå¸¸ç®€å•ï¼Œä½¿ç”¨ä½ å–œæ¬¢çš„æµ‹è¯•æ¡†æ¶ï¼Œä¼ é€’åˆé€‚çš„è¾“å…¥çš„å‚æ•°å¹¶éªŒè¯è¾“å‡ºç»“æœã€‚

```java
@Test
void testIncrement() throws Exception {
    // å®ä¾‹åŒ–ä½ çš„å‡½æ•°
    IncrementMapFunction incrementMapFunction = new IncrementMapFunction();
    // è°ƒç”¨å®ç°çš„æ–¹æ³•
    assertThat(incrementMapFunction.map(2L)).isEqualTo(3L);
}
```

ç±»ä¼¼åœ°ï¼Œä¸€ä¸ªä½¿ç”¨ `org.apache.flink.util.Collector`ï¼ˆå¦‚ï¼š`FlatMapFunction` ï¼Œ`ProcessFunction`ï¼‰çš„ UDF å¯ä»¥é€šè¿‡æä¾›ä¸€ä¸ªæ¨¡æ‹Ÿå¯¹è±¡æ¥æ›¿ä»£çœŸå®çš„ `Collector` å¯¹è±¡å»è½»æ¾çš„è¿›è¡Œæµ‹è¯•ã€‚

ä¸€ä¸ªå…·æœ‰å’Œ `IncrementMapFunction` åŒæ ·çš„åŠŸèƒ½ `FlatMapFunction` æµ‹è¯•æ¡ˆä¾‹å¦‚ä¸‹ï¼š

```java
@Test
void testIncrement(@Mock Collector<Long> collector) throws Exception {
    // å®ä¾‹åŒ–
    IncrementFlatMapFunction increment = new IncrementFlatMapFunction();
    // è°ƒç”¨å®ç°çš„æ–¹æ³•
    increment.flatMap(2L, collector);
    // éªŒè¯ä½¿ç”¨æ­£ç¡®çš„è¾“å‡ºè°ƒç”¨äº†æ”¶é›†å™¨
    Mockito.verify(collector, times(1)).collect(3L);
}
```

### å•å…ƒæµ‹è¯• Stateful,Timely UDFs å’Œè‡ªå®šä¹‰ç®—å­

å¯¹ä½¿ç”¨äº†æ‰˜ç®¡çŠ¶æ€ï¼ˆstateï¼‰æˆ–å®šæ—¶å™¨ï¼ˆtimerï¼‰çš„ UDF çš„åŠŸèƒ½è¿›è¡Œæµ‹è¯•éš¾åº¦ç›¸å¯¹å¤§ä¸€äº›ï¼Œå› ä¸ºå®ƒæ¶‰åŠæµ‹è¯•ç”¨æˆ·ä»£ç å’Œ Flink è¿è¡Œæ—¶ï¼ˆruntimeï¼‰ä¹‹é—´çš„äº¤äº’ã€‚ä¸ºæ­¤ï¼ŒFlink æä¾›äº†ä¸€ç³»åˆ—å«åš `test harnesses` çš„æµ‹è¯•å·¥å…·ï¼Œèƒ½å¤Ÿå¸®åŠ©æˆ‘ä»¬æµ‹è¯•æ­¤ç±»ç”¨æˆ·å®šä¹‰çš„å‡½æ•°ä»¥åŠè‡ªå®šä¹‰ç®—å­ï¼š

- `OneInputStreamOperatorTestHarness` ï¼ˆç”¨äºåŸºäº `DataStream` çš„ç®—å­ï¼‰
- `KeyedOneInputStreamOperatorTestHarness`ï¼ˆç”¨äºåŸºäº `KeyedStream` çš„ç®—å­ï¼‰
- `TwoInputStreamOperatorTestHarness`ï¼ˆç”¨äºåŸºäºä¸¤ä¸ª `DataStream` çš„ `ConnectedStream` çš„ç®—å­ï¼‰
- `KeyedTwoInputStreamOperatorTestHarness`ï¼ˆç”¨äºåŸºäºä¸¤ä¸ª `KeyedStream` çš„ `ConnectedStream` çš„ç®—å­ï¼‰

è¦ä½¿ç”¨è¿™äº› `test harnesses` ä½ éœ€è¦å¼•å…¥é¢å¤–çš„ä¾èµ–ï¼Œå‚è€ƒ [Flink å•å…ƒæµ‹è¯•(ä¸€)](ut1.md)ã€‚

å¦‚æœéœ€è¦å¯¹ Table API è¿›è¡Œæµ‹è¯•ï¼Œè¿˜éœ€è¦å¼•å…¥ `flink-table-test-utils` ä¾èµ–ï¼Œå®ƒæ˜¯åœ¨ Flink 1.15 ç‰ˆæœ¬å¼•å…¥çš„ï¼Œç›®å‰è¿˜å¤„äº experimentalï¼ˆå®éªŒæ€§ï¼‰é˜¶æ®µã€‚

```xml
<dependency>
    <groupId>org.apache.flink</groupId>
    <artifactId>flink-table-test-utils</artifactId>
    <version>1.15.0</version>
    <scope>test</scope>
</dependency>
```

ç°åœ¨ï¼Œä½ å¯ä»¥ä½¿ç”¨ `test harnesses` å°†è¾“å…¥æ•°æ®å’Œæ°´å°ï¼ˆwatermarksï¼‰æ¨é€åˆ°ç”¨æˆ·å®šä¹‰çš„å‡½æ•°ï¼ˆUDFï¼‰æˆ–è‡ªå®šä¹‰ç®—å­ä¸­ï¼Œå¹¶æ§åˆ¶å¤„ç†æ—¶é—´å’Œå¯¹ç®—å­çš„è¾“å‡ºè¿›è¡Œæœ€ç»ˆçš„æ–­è¨€ï¼ˆåŒ…æ‹¬ä¾§è¾¹æµè¾“å‡ºï¼‰ã€‚

è®©æˆ‘ä»¬å®ç°ä¸€ä¸ªç®€å•çš„æœ‰çŠ¶æ€çš„ `FlatMapFunction` ç®—å­ï¼š

```java
public class StatefulFlatMapFunction implements CheckpointedFunction, FlatMapFunction<Long, Long> {  
  
    private static final long serialVersionUID = 1L;  
    private static final ListStateDescriptor<Long> MAX_VALUE_STATE_DESC =  
            new ListStateDescriptor<>("maxValueState", Types.LONG);  
  
    private transient ListState<Long> maxValueState;  
  
    @Override  
    public void flatMap(Long value, Collector<Long> out) throws Exception {  
        Long maxValue = value;  
        Iterable<Long> longIterable = maxValueState.get();  
        if (longIterable != null) {  
            for (Long preMaxValue: longIterable) {  
                maxValue = Math.max(preMaxValue, maxValue);  
            }  
        }  
        maxValueState.update(Lists.newArrayList(maxValue));  
        out.collect(maxValue);  
    }  
  
    @Override  
    public void snapshotState(FunctionSnapshotContext context) throws Exception {  
        // do nothing  
    }  
  
    @Override  
    public void initializeState(FunctionInitializationContext context) throws Exception {  
        maxValueState = context.getOperatorStateStore().getListState(MAX_VALUE_STATE_DESC);  
    }  
}
```

è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•ä½¿ç”¨ `test harnesses` ä¸ºå…¶ç¼–å†™æµ‹è¯•æ¡ˆä¾‹ï¼š

```java
class StatefulFlatMapFunctionTest {  
    
    private OneInputStreamOperatorTestHarness<Long, Long> testHarness;  
  
    @BeforeEach  
    void setupTestHarness() throws Exception {  
        // å®ä¾‹åŒ– UDF        
        StatefulFlatMapFunction statefulFlatMapFunction = new StatefulFlatMapFunction();  
        // å°† UDF åŒ…è£…åˆ°ç›¸åº”çš„ TestHarness ä¸­  
        testHarness = new OneInputStreamOperatorTestHarness<>(new StreamFlatMap<>(statefulFlatMapFunction));  
        // å¯é€‰åœ°é…ç½®æ‰§è¡Œç¯å¢ƒ  
        testHarness.getExecutionConfig().setAutoWatermarkInterval(50);  
        // æ‰“å¼€ testHarness(ä¹Ÿä¼šè°ƒç”¨ RichFunctions çš„ open æ–¹æ³•)  
        testHarness.open();  
    }  
  
    @Test
	void testingStatefulFlatMapFunction() throws Exception {  
	    // æ¨é€å…ƒç´ åŠä¸è¯¥å…ƒç´ å…³è”çš„æ—¶é—´æˆ³è‡³ç®—å­ä¸­ 
	    testHarness.processElement(2L, 100L);   
	    // é€šè¿‡ä½¿ç”¨æ°´å°æ¨è¿›ç®—å­çš„äº‹ä»¶æ—¶é—´æ¥è§¦å‘äº‹ä»¶æ—¶é—´ timer 
	    testHarness.processWatermark(100L);  
	    // é€šè¿‡ç›´æ¥æå‰ç®—å­çš„å¤„ç†æ—¶é—´æ¥è§¦å‘å¤„ç†æ—¶é—´ timer 
	    testHarness.setProcessingTime(100L); 
        
	    // è·å–è¾“å‡ºåˆ—è¡¨ç”¨äºæ–­è¨€ï¼ˆåŒ…å« watermarkï¼‰  
	    // åœ¨ flink ä¸­æ°´å°ï¼ˆwatermarkï¼‰å°±æ˜¯é€šè¿‡æ¨é€ä¸€æ¡è®°å½•å®ç°çš„ï¼Œè¿™æ¡è®°å½•åªæœ‰æ—¶é—´æˆ³ã€‚  
	    assertThat(testHarness.getOutput().toArray())  
            .isEqualTo(Arrays.array(  
                    new StreamRecord<>(2L, 100L),  
                    new Watermark(100L)  
            ));  
        
        // æ¨é€å…ƒç´ åŠä¸è¯¥å…ƒç´ å…³è”çš„æ—¶é—´æˆ³è‡³ç®—å­ä¸­ 
        testHarness.processElement(6L, 110);
        
        // è·å–è¾“å‡ºåˆ—è¡¨ç”¨äºæ–­è¨€ï¼Œç›´æ¥è·å–å€¼ 
        assertThat(testHarness.extractOutputValues())  
            .isEqualTo(Lists.newArrayList(2L, 6L));  
        
        // è·å– operator çŠ¶æ€ç”¨äºæ–­è¨€
        ListState<Long> maxValueState = testHarness.getOperator()
                .getOperatorStateBackend()
                .getListState(new ListStateDescriptor<>("maxValueState", Types.LONG));
        assertThat(maxValueState.get()).isEqualTo(Lists.newArrayList(6L));
            
        // è·å–ä¾§è¾¹æµçš„è¾“å‡ºç”¨äºæ–­è¨€ï¼ˆä»…åœ¨ ProcessFunction å¯ç”¨ï¼‰
        //assertThat(testHarness.getSideOutput(new OutputTag<>("invalidRecords")), hasSize(0))  
	}    
}
```

æ¥ä¸‹æ¥æˆ‘ä»¬çœ‹ä¸€ä¸‹å¦‚ä½•ä¸ºåŒæ ·é€»è¾‘çš„ `KeyedStream` ç®—å­è¿›è¡Œæµ‹è¯•ã€‚

å¯¹äº `KeyedStream` ç®—å­çš„æµ‹è¯•ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ `KeyedOneInputStreamOperatorTestHarness` å’Œ `KeyedTwoInputStreamOperatorTestHarness`ï¼Œå¯¹æ­¤æˆ‘ä»¬éœ€è¦é¢å¤–æä¾› `KeySelector` å’Œ `Key` çš„ç±»å‹å»åˆ›å»ºå®ƒä»¬ã€‚å¦‚ä¸‹ï¼š

```java
class KeyedStatefulFlatMapFunctionTest {

    private OneInputStreamOperatorTestHarness<Long, Long> testHarness;
    private KeyedStatefulFlatMapFunction keyedStatefulFlatMapFunction;

    @BeforeEach
    void setupTestHarness() throws Exception {
        // å®ä¾‹åŒ– UDF
        keyedStatefulFlatMapFunction = new KeyedStatefulFlatMapFunction();
        // å°† UDF åŒ…è£…åˆ°ç›¸åº”çš„ TestHarness ä¸­
        // é™¤äº†ä¼ é€’ UDF å®ä¾‹ï¼Œè¿˜éœ€è¦ KeySelector, Key çš„ç±»å‹
        testHarness = new KeyedOneInputStreamOperatorTestHarness<>(
                new StreamFlatMap<>(keyedStatefulFlatMapFunction), (el) -> "1", Types.STRING);
        // æ‰“å¼€ testHarness(ä¹Ÿä¼šè°ƒç”¨ RichFunctions çš„ open æ–¹æ³•)
        testHarness.open();
    }

    @Test
    void testingStatefulFlatMapFunction() throws Exception {
        // æ¨é€å…ƒç´ åŠä¸è¯¥å…ƒç´ å…³è”çš„æ—¶é—´æˆ³è‡³ç®—å­ä¸­
        testHarness.processElement(2L, 100L);
        
        // è·å–è¾“å‡ºåˆ—è¡¨ç”¨äºæ–­è¨€
        assertThat(testHarness.extractOutputValues())
                .isEqualTo(Lists.newArrayList(2L));
        
		// æ¨é€å…ƒç´ åŠä¸è¯¥å…ƒç´ å…³è”çš„æ—¶é—´æˆ³è‡³ç®—å­ä¸­ 
        testHarness.processElement(6L, 110L);
        
        // è·å– keyed çŠ¶æ€ç”¨äºæ–­è¨€ï¼Œkeyed çŠ¶æ€æˆ‘ä»¬å¯ä»¥ç›´æ¥é€šè¿‡ç®—å­çš„ getRuntimeContext è·å–
        // å½“ç„¶ä¹Ÿå¯ä»¥ä½¿ç”¨ testHarness è·å–
        ListState<Long> maxValueState = keyedStatefulFlatMapFunction.getRuntimeContext()
                .getListState(new ListStateDescriptor<>("maxValueState", Types.LONG));
        assertThat(maxValueState.get()).isEqualTo(Lists.newArrayList(6L));
    }
}
```

æ›´å¤šå…³äº `test harnesses` çš„ä½¿ç”¨æ¡ˆä¾‹å¯ä»¥åœ¨ [Flink ä»£ç ä»“åº“](https://github.com/apache/flink/tree/master/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/operators/windowing)æ‰¾åˆ°ï¼š

- `org.apache.flink.streaming.runtime.operators.windowing.WindowOperatorTest` æ˜¯ä¸€ä¸ªæµ‹è¯•åŸºäºå¤„ç†æˆ–äº‹ä»¶æ—¶é—´çš„ç®—å­å’Œç”¨æˆ·å®šä¹‰å‡½æ•°ï¼ˆUDFï¼‰çš„å¾ˆå¥½ä¾‹å­ã€‚

>[!note]
>è¯·æ³¨æ„ï¼Œ`AbstractStreamOperatorTestHarness` åŠå…¶æ´¾ç”Ÿç±»ç›®å‰ä¸æ˜¯å…¬å…± API çš„ä¸€éƒ¨åˆ†ï¼Œå¯èƒ½ä¼šå‘ç”Ÿå˜åŒ–.ã€‚

### å•å…ƒæµ‹è¯• ProcessFunction

é‰´äºå®ƒçš„é‡è¦æ€§ï¼Œé™¤äº†èƒ½å¤Ÿç›´æ¥ä½¿ç”¨å‰é¢æåˆ°çš„ `test harnesses` å¯¹ `ProcessFunction` è¿›è¡Œæµ‹è¯•ä¹‹å¤–ï¼ŒFlink è¿˜æä¾›äº†ä¸€ä¸ªåä¸º `ProcessFunctionTestHarnesses` çš„æµ‹è¯•å·¥å…·å·¥å‚ç±»ï¼Œä»¥ä¾¿ç®€åŒ–æµ‹è¯•å·¥å…·ï¼ˆ`test harness`ï¼‰çš„å®ä¾‹åŒ–ï¼Œè®©æˆ‘ä»¬çœ‹ä¸€ä¸ªä¾‹å­ï¼š

```java
public class PassThroughProcessFunction extends ProcessFunction<Integer, Integer> {  
  
    private static final long serialVersionUID = 1L;  
  
    @Override  
    public void processElement(Integer value,  
                               ProcessFunction<Integer, Integer>.Context context,  
                               Collector<Integer> out) throws Exception {  
        out.collect(value);  
    }  
}
```

ä½¿ç”¨ `ProcessFunctionTestHarnesses` å¯¹  `ProcessFunction` è¿›è¡Œæµ‹è¯•éå¸¸ç®€å•ï¼Œä¼ é€’åˆé€‚çš„å‚æ•°å¹¶éªŒè¯è¾“å‡ºï¼š

```java
class PassThroughProcessFunctionTest {  
  
    @Test
    void testPassThrough() throws Exception {
        // å®ä¾‹åŒ– UDF
        PassThroughProcessFunction processFunction = new PassThroughProcessFunction();

        // åŒ…è£… UDF è‡³ç›¸åº”çš„ TestHarness ä¸­
        OneInputStreamOperatorTestHarness<Integer, Integer> testHarness =
                ProcessFunctionTestHarnesses.forProcessFunction(processFunction);

        // æ¨é€å…ƒç´ åŠä¸è¯¥å…ƒç´ å…³è”çš„æ—¶é—´æˆ³è‡³ç®—å­ä¸­
        testHarness.processElement(1, 10);

        // è·å–è¾“å‡ºå¹¶æ–­è¨€
        assertThat(testHarness.extractOutputValues())
                .isEqualTo(Collections.singletonList(1));
    }
  
}
```

æœ‰å…³å¦‚ä½•ä½¿ç”¨ `ProcessFunctionTestHarnesses` æ¥æµ‹è¯•ä¸åŒç±»å‹çš„ `ProcessFunction`ï¼ˆå¦‚ `KeyedProcessFunction`, `KeyedCoProcessFunction`,Â `BroadcastProcessFunction`ï¼‰çš„æ›´å¤šç¤ºä¾‹ï¼Œå¯ä»¥æŸ¥çœ‹ [Flink ä»£ç ä»“åº“](https://github.com/apache/flink/tree/master/flink-streaming-java/src/test/java/org/apache/flink/streaming/util) çš„ `ProcessFunctionTestHarnessesTest`ã€‚

## æµ‹è¯• Flink Job

### JUnit 4 Rule MiniClusterWithClientResource

åœ¨ JUnit 4 ä¸­ Apache Flink æä¾›äº†ä¸€ä¸ªåä¸º  `MiniClusterWithClientResource` çš„ Ruleï¼ˆè§„åˆ™ï¼‰ï¼Œç”¨äºåœ¨æœ¬åœ°åµŒå…¥ä¸€ä¸ªè¿·ä½ é›†ç¾¤ï¼Œä»¥ä¾¿æµ‹è¯•å®Œæ•´çš„ Jobã€‚

è®©æˆ‘ä»¬ä»¥ä¸Šé¢æåˆ°çš„ `IncrementMapFunction` ä¸ºä¾‹ï¼Œåœ¨æœ¬åœ° Flink é›†ç¾¤æµ‹è¯•ä¸€ä¸ªä½¿ç”¨ `MapFunction` çš„ç®€å• Jobï¼š

```java
public class JUnit4ExampleIntegrationTest {  
  
    @ClassRule  
    public static MiniClusterWithClientResource flinkCluster = new MiniClusterWithClientResource(  
            new MiniClusterResourceConfiguration.Builder()  
                    .setNumberSlotsPerTaskManager(2)  
                    .setNumberTaskManagers(1)  
                    .build());  
  
    @Test  
    public void testIncrementPipeline() throws Exception {  
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();  
  
        // configure your test environment  
        env.setParallelism(2);  
  
        // values are collected in a static variable  
        CollectSink.values.clear();  
  
        // create a stream of custom elements and apply transformations  
        env.fromElements(1L, 21L, 22L)  
                .map(new IncrementMapFunction())  
                .addSink(new CollectSink());  
  
        // execute  
        env.execute();  
  
        // verify your results  
        assertTrue(CollectSink.values.containsAll(Lists.list(2L, 22L, 23L)));  
    }  
  
    // create a testing sink  
    private static class CollectSink implements SinkFunction<Long> {  
  
        // must be static  
        public static final List<Long> values = Collections.synchronizedList(new ArrayList<>());  
  
        @Override  
        public void invoke(Long value, SinkFunction.Context context) throws Exception {  
            values.add(value);  
        }  
    }  
}
```

å…³äºä½¿ç”¨ `MiniClusterWithClientResource` é›†æˆæµ‹è¯•çš„å‡ ç‚¹è¯´æ˜ï¼š

- ä¸ºäº†é¿å…åœ¨æµ‹è¯•æ—¶æ‹·è´æ•´ä¸ª job pipeline çš„ä»£ç ï¼Œä½ éœ€è¦å°†ä½ ç”Ÿäº§ä»£ç çš„ source å’Œ sink è®¾è®¡æˆå¯æ’æ‹”çš„ï¼Œä»¥ä¾¿åœ¨æµ‹è¯•ä¸­æ³¨å…¥ç‰¹æ®Šçš„æµ‹è¯•çš„ source å’Œ æµ‹è¯•çš„ sinkã€‚
- è¿™é‡Œä½¿ç”¨Â `CollectSink`Â ä¸­çš„é™æ€å˜é‡ï¼Œæ˜¯å› ä¸º Flink åœ¨å°†æ‰€æœ‰ç®—å­åˆ†å¸ƒåˆ°æ•´ä¸ªé›†ç¾¤ä¹‹å‰å…ˆå¯¹å…¶è¿›è¡Œäº†åºåˆ—åŒ–ï¼Œè§£å†³æ­¤é—®é¢˜çš„æ–¹æ³•ä¹‹ä¸€æ˜¯ä¸æœ¬åœ° Flink è¿·ä½ é›†ç¾¤é€šè¿‡å®ä¾‹åŒ–ç®—å­çš„é™æ€å˜é‡è¿›è¡Œé€šä¿¡ï¼Œæˆ–è€…ï¼Œä½ å¯ä»¥ä½¿ç”¨æµ‹è¯•çš„sink å°†æ•°æ®å†™å…¥ä¸´æ—¶ç›®å½•ä¸­çš„æ–‡ä»¶ã€‚
- å¦‚æœä½ çš„ job ä½¿ç”¨äº†äº‹ä»¶æ—¶é—´ timer ï¼Œä½ å¯ä»¥å®ç°è‡ªå®šä¹‰çš„å¹¶è¡Œ source å‡½æ•°æ¥å‘é€æ°´å°ï¼ˆwatermarkï¼‰ã€‚
- å»ºè®®å§‹ç»ˆä½¿ç”¨ `parallelsim > 1` çš„æ–¹å¼åœ¨æœ¬åœ°æµ‹è¯• pipelineï¼Œä»¥ä¾¿å‘ç°é‚£äº›åªæœ‰ pipeline åœ¨å¹¶è¡Œæ‰§è¡Œæ—¶æ‰ä¼šå‡ºç°çš„ bugã€‚
- ä¼˜å…ˆä½¿ç”¨ `@ClassRule` è€Œä¸æ˜¯ `@Rule`ï¼Œè¿™æ ·å¤šä¸ªæµ‹è¯•èƒ½å¤Ÿå…±äº«åŒä¸€ä¸ª Flink é›†ç¾¤ï¼Œè¿™æ ·åšèƒ½å¤ŸèŠ‚çº¦å¤§é‡çš„æ—¶é—´ï¼Œå› ä¸º Flink é›†ç¾¤çš„å¯åŠ¨å’Œå…³é—­é€šå¸¸å æ®äº†å®é™…æµ‹è¯•çš„æ‰§è¡Œæ—¶é—´ã€‚
- å¦‚æœä½ çš„ pipeline åŒ…å«è‡ªå®šä¹‰çŠ¶æ€å¤„ç†ï¼Œåˆ™å¯ä»¥é€šè¿‡å¯ç”¨ checkpoint å¹¶åœ¨è¿·ä½ é›†ç¾¤ä¸­é‡æ–°å¯åŠ¨ä½œä¸šæ¥æµ‹è¯•å…¶æ­£ç¡®æ€§ï¼Œä¸ºæ­¤ï¼Œä½ éœ€è¦åœ¨ pipeline çš„ï¼ˆä»…åœ¨æµ‹è¯•ä½¿ç”¨çš„ï¼‰ç”¨æˆ·è‡ªå®šä¹‰å‡½æ•°ä¸­æŠ›å‡ºå¼‚å¸¸æ¥è§¦å‘å¤±è´¥ã€‚

### JUnit 5  MiniClusterExtension

åœ¨ JUnit 5 ä¸­å·²ä¸å†æ”¯æŒ `@ClassRule` å’Œ `@Rule`ï¼Œåˆ†åˆ«ä½¿ç”¨ `@RegisterExtension` å’Œ `@ExtendWith` å»æ›¿æ¢ã€‚

åœ¨ JUnit 5 ä¸­ï¼ŒFlink æä¾›äº† `MiniClusterExtension` çš„æ‰©å±•ç”¨äºåœ¨æœ¬åœ°å¯åŠ¨ä¸€ä¸ª Flink é›†ç¾¤å¹¶æ³¨å†Œç›¸åº”çš„æ‰§è¡Œç¯å¢ƒï¼Œä½¿ç”¨ JUnit 5 ç¼–å†™  `IncrementMapFunction` Job çš„æµ‹è¯•ç”¨ä¾‹å¦‚ä¸‹ï¼š

```java
@ExtendWith(MiniClusterExtension.class)
class JUnit5ExampleIntegrationTest {
	@Test
	void testIncrementPipeline() {
		ExecutionEnvironment execEnv = ExecutionEnvironment.getExecutionEnvironment();
		//...omit
	}
}
```

å¦‚æœéœ€è¦è°ƒæ•´é›†ç¾¤çš„é…ç½®ï¼Œä½ å¯ä»¥ä½¿ç”¨ `@RegisterExtension` ï¼š
```java
class JUnit5ExampleIntegrationTest {

	@RegisterExtension
	public static final MiniClusterExtension MINI_CLUSTER_RESOURCE = new 
		MiniClusterExtension(
			new MiniClusterResourceConfiguration.Builder()
				 .setNumberTaskManagers(1)
				 .setConfiguration(new Configuration())
				 .build());
		
	@Test
	void testIncrementPipeline() {
		ExecutionEnvironment execEnv = ExecutionEnvironment.getExecutionEnvironment();
		//...omit
	}
}
```

## æ€»ç»“

æœ¬èŠ‚æˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•åœ¨ Apache Flink ä¸­ä¸º **æ— çŠ¶æ€ã€æœ‰çŠ¶æ€å’Œæ—¶é—´æ„ŸçŸ¥ï¼ˆtimerï¼‰** çš„ç®—å­ç¼–å†™å•å…ƒæµ‹è¯•ï¼Œä»¥åŠå¦‚ä½•ä¸º Job è¿›è¡Œé›†æˆæµ‹è¯•ã€‚

ğŸ‘‹ [è®¿é—® GitHub è·å–æºä»£ç ](https://github.com/xbhel/flink-starter/tree/main/flink-unit-test)ã€‚


